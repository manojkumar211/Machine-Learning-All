{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature scaling is a crucial preprocessing step in machine learning that ensures all features contribute equally to the model's performance. It involves transforming the values of features in your dataset to a common scale without distorting the relationships between them. This is particularly important when features have different units or magnitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Use Feature Scaling?\n",
    "- Improves Model Convergence:\n",
    "- Algorithms like gradient descent converge faster when features are scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevents Dominance:\n",
    "- Features with larger magnitudes can dominate those with smaller magnitudes in distance-based algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhances Performance:\n",
    "- Scaling ensures fair weight distribution for machine learning models sensitive to feature magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Feature Scaling\n",
    "- Feature scaling is especially important for machine learning algorithms that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use distance metrics (e.g., K-Nearest Neighbors, K-Means, SVM).\n",
    "- Involve gradient-based optimization (e.g., Neural Networks, Logistic Regression).\n",
    "- Are sensitive to feature magnitudes (e.g., Principal Component Analysis).\n",
    "- Some algorithms, like tree-based methods (e.g., Random Forest, Decision Trees, XGBoost), are generally insensitive to feature scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Scaling Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaling (Normalization):\n",
    "\n",
    "- Transforms features to a fixed range, usually \n",
    "[\n",
    "0\n",
    ",\n",
    "1\n",
    "]\n",
    "[0,1].\n",
    "- Formula:\n",
    "ğ‘‹\n",
    "â€²\n",
    "=\n",
    "ğ‘‹\n",
    "âˆ’\n",
    "ğ‘‹\n",
    "min\n",
    "ğ‘‹\n",
    "max\n",
    "âˆ’\n",
    "ğ‘‹\n",
    "min\n",
    "X \n",
    "â€²\n",
    " = \n",
    "X \n",
    "max\n",
    "â€‹\n",
    " âˆ’X \n",
    "min\n",
    "â€‹\n",
    " \n",
    "Xâˆ’X \n",
    "min\n",
    "â€‹\n",
    " \n",
    "â€‹\n",
    " \n",
    "- Pros: Maintains original distribution.\n",
    "- Cons: Sensitive to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization (Z-score Normalization):\n",
    "\n",
    "- Centers the data around zero with a unit variance.\n",
    "- Formula:\n",
    "ğ‘‹\n",
    "â€²\n",
    "=\n",
    "ğ‘‹\n",
    "âˆ’\n",
    "ğœ‡\n",
    "ğœ\n",
    "X \n",
    "â€²\n",
    " = \n",
    "Ïƒ\n",
    "Xâˆ’Î¼\n",
    "â€‹\n",
    " \n",
    "- Where \n",
    "ğœ‡\n",
    "Î¼ is the mean and \n",
    "ğœ\n",
    "Ïƒ is the standard deviation.\n",
    "- Pros: Robust for normally distributed data.\n",
    "- Cons: Assumes Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Scaling:\n",
    "\n",
    "- Uses the median and interquartile range to scale features.\n",
    "- Formula:\n",
    "ğ‘‹\n",
    "â€²\n",
    "=\n",
    "ğ‘‹\n",
    "âˆ’\n",
    "median\n",
    "(\n",
    "ğ‘‹\n",
    ")\n",
    "IQR\n",
    "(\n",
    "ğ‘‹\n",
    ")\n",
    "X \n",
    "â€²\n",
    " = \n",
    "IQR(X)\n",
    "Xâˆ’median(X)\n",
    "â€‹\n",
    " \n",
    "- Pros: Handles outliers well.\n",
    "- Cons: Can distort non-linear relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxAbs Scaling:\n",
    "\n",
    "- Scales data to the range ([-1, 1]] by dividing by the maximum absolute value.\n",
    "Useful for sparse data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Transformation:\n",
    "\n",
    "- Reduces skewness by transforming data using \n",
    "log\n",
    "â¡\n",
    "(\n",
    "ğ‘‹\n",
    ")\n",
    "log(X).\n",
    "- Best for data with exponential or positively skewed distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile Transformation:\n",
    "\n",
    "- Maps data to a uniform or normal distribution using quantiles.\n",
    "- Pros: Handles outliers effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Min-Max Scaling (Normalization)\n",
    "Description:\n",
    "\n",
    "Scales the data to a range, typically [ 0 , 1 ] [0,1]. Formula: ğ‘‹ â€² = ğ‘‹ âˆ’ ğ‘‹ min ğ‘‹ max âˆ’ ğ‘‹ min X â€² = X maxâ€‹âˆ’X minâ€‹\n",
    "\n",
    "Xâˆ’X minâ€‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-Max Scaled Data:\n",
      " [[0.         0.        ]\n",
      " [0.33333333 0.125     ]\n",
      " [0.66666667 0.5       ]\n",
      " [1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "data = np.array([[1, 10], [2, 15], [3, 30], [4, 50]])\n",
    "\n",
    "# Apply Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "data_min_max_scaled = scaler.fit_transform(data)\n",
    "\n",
    "print(\"Min-Max Scaled Data:\\n\", data_min_max_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Standardization (Z-score Normalization)\n",
    "Description:\n",
    "\n",
    "Centers the data to have a mean of 0 and a standard deviation of 1. Formula: ğ‘‹ â€² = ğ‘‹ âˆ’ ğœ‡ ğœ X â€² = Ïƒ Xâˆ’Î¼â€‹\n",
    "\n",
    "Where ğœ‡ Î¼ is the mean and ğœ Ïƒ is the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Data:\n",
      " [[-1.34164079 -1.04418513]\n",
      " [-0.4472136  -0.7228974 ]\n",
      " [ 0.4472136   0.2409658 ]\n",
      " [ 1.34164079  1.52611672]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Apply Standardization\n",
    "scaler = StandardScaler()\n",
    "data_standard_scaled = scaler.fit_transform(data)\n",
    "\n",
    "print(\"Standardized Data:\\n\", data_standard_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Robust Scaling\n",
    "Description:\n",
    "\n",
    "Scales the data based on the median and interquartile range (IQR), making it robust to outliers. Formula: ğ‘‹ â€² = ğ‘‹ âˆ’ median ( ğ‘‹ ) IQR ( ğ‘‹ ) X â€² = IQR(X) Xâˆ’median(X)â€‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robust Scaled Data:\n",
      " [[-1.         -0.58823529]\n",
      " [-0.33333333 -0.35294118]\n",
      " [ 0.33333333  0.35294118]\n",
      " [ 1.          1.29411765]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Apply Robust Scaling\n",
    "scaler = RobustScaler()\n",
    "data_robust_scaled = scaler.fit_transform(data)\n",
    "\n",
    "print(\"Robust Scaled Data:\\n\", data_robust_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MaxAbs Scaling\n",
    "Description:\n",
    "\n",
    "Scales each feature by its maximum absolute value, resulting in a range of ([-1, 1]]. Formula: ğ‘‹ â€² = ğ‘‹ max ( âˆ£ ğ‘‹ âˆ£ ) X â€² = max(âˆ£Xâˆ£) Xâ€‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxAbs Scaled Data:\n",
      " [[0.25 0.2 ]\n",
      " [0.5  0.3 ]\n",
      " [0.75 0.6 ]\n",
      " [1.   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# Apply MaxAbs Scaling\n",
    "scaler = MaxAbsScaler()\n",
    "data_maxabs_scaled = scaler.fit_transform(data)\n",
    "\n",
    "print(\"MaxAbs Scaled Data:\\n\", data_maxabs_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Log Transformation\n",
    "Description:\n",
    "\n",
    "Reduces skewness by applying the logarithm function. Typically used for positively skewed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Transformed Data:\n",
      " [[0.69314718 2.39789527]\n",
      " [1.09861229 2.77258872]\n",
      " [1.38629436 3.4339872 ]\n",
      " [1.60943791 3.93182563]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Apply Log Transformation\n",
    "data_log_transformed = np.log1p(data)  # log1p adds 1 to avoid log(0)\n",
    "\n",
    "print(\"Log Transformed Data:\\n\", data_log_transformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quantile Transformation\n",
    "Description:\n",
    "\n",
    "Transforms features to follow a uniform or normal distribution using quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature scaling is a crucial preprocessing step in machine learning that ensures all features contribute equally to the model's performance. It involves transforming the values of features in your dataset to a common scale without distorting the relationships between them. This is particularly important when features have different units or magnitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Use Feature Scaling?\n",
    "- Improves Model Convergence:\n",
    "- Algorithms like gradient descent converge faster when features are scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevents Dominance:\n",
    "- Features with larger magnitudes can dominate those with smaller magnitudes in distance-based algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhances Performance:\n",
    "- Scaling ensures fair weight distribution for machine learning models sensitive to feature magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Feature Scaling\n",
    "- Feature scaling is especially important for machine learning algorithms that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use distance metrics (e.g., K-Nearest Neighbors, K-Means, SVM).\n",
    "- Involve gradient-based optimization (e.g., Neural Networks, Logistic Regression).\n",
    "- Are sensitive to feature magnitudes (e.g., Principal Component Analysis).\n",
    "- Some algorithms, like tree-based methods (e.g., Random Forest, Decision Trees, XGBoost), are generally insensitive to feature scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Scaling Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaling (Normalization):\n",
    "\n",
    "- Transforms features to a fixed range, usually \n",
    "[\n",
    "0\n",
    ",\n",
    "1\n",
    "]\n",
    "[0,1].\n",
    "- Formula:\n",
    "ğ‘‹\n",
    "â€²\n",
    "=\n",
    "ğ‘‹\n",
    "âˆ’\n",
    "ğ‘‹\n",
    "min\n",
    "ğ‘‹\n",
    "max\n",
    "âˆ’\n",
    "ğ‘‹\n",
    "min\n",
    "X \n",
    "â€²\n",
    " = \n",
    "X \n",
    "max\n",
    "â€‹\n",
    " âˆ’X \n",
    "min\n",
    "â€‹\n",
    " \n",
    "Xâˆ’X \n",
    "min\n",
    "â€‹\n",
    " \n",
    "â€‹\n",
    " \n",
    "- Pros: Maintains original distribution.\n",
    "- Cons: Sensitive to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization (Z-score Normalization):\n",
    "\n",
    "- Centers the data around zero with a unit variance.\n",
    "- Formula:\n",
    "ğ‘‹\n",
    "â€²\n",
    "=\n",
    "ğ‘‹\n",
    "âˆ’\n",
    "ğœ‡\n",
    "ğœ\n",
    "X \n",
    "â€²\n",
    " = \n",
    "Ïƒ\n",
    "Xâˆ’Î¼\n",
    "â€‹\n",
    " \n",
    "- Where \n",
    "ğœ‡\n",
    "Î¼ is the mean and \n",
    "ğœ\n",
    "Ïƒ is the standard deviation.\n",
    "- Pros: Robust for normally distributed data.\n",
    "- Cons: Assumes Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Scaling:\n",
    "\n",
    "- Uses the median and interquartile range to scale features.\n",
    "- Formula:\n",
    "ğ‘‹\n",
    "â€²\n",
    "=\n",
    "ğ‘‹\n",
    "âˆ’\n",
    "median\n",
    "(\n",
    "ğ‘‹\n",
    ")\n",
    "IQR\n",
    "(\n",
    "ğ‘‹\n",
    ")\n",
    "X \n",
    "â€²\n",
    " = \n",
    "IQR(X)\n",
    "Xâˆ’median(X)\n",
    "â€‹\n",
    " \n",
    "- Pros: Handles outliers well.\n",
    "- Cons: Can distort non-linear relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxAbs Scaling:\n",
    "\n",
    "- Scales data to the range ([-1, 1]] by dividing by the maximum absolute value.\n",
    "Useful for sparse data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
